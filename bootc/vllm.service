[Unit]
Description=vLLM OpenAI-compatible API server
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
Environment=VLLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
Environment=HOST=0.0.0.0
Environment=PORT=8000
Environment=DTYPE=float32
Environment=VLLM_EXTRA_ARGS=
ExecStart=/usr/local/bin/start-vllm
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target


